{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AINI:Academy1 Tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Mdv3nR_jb-zG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# AI NI Academy 1 - Tutorial\n",
        "\n",
        "***\n",
        "\n",
        "![AI NI Academy](https://www.scipy-lectures.org/_images/scikit-learn-logo.png)\n",
        "\n",
        "***\n",
        "\n",
        "Scikit-Learn provides us with different **supervised and unsupervised algorithms** via the use of the most popular scripting language, **Python**. \n",
        "\n",
        "\n",
        "The library is **built upon SciPy** which must be installed before you can use scikit-learn. \n",
        "\n",
        "The Scikit-Learn package consists of:\n",
        "\n",
        "*   **NumPy**: Base n-dimensional array package\n",
        "*   **SciPy**: Fundamental library for scientific computing\n",
        "*   **Matplotlib**: Comprehensive 2D/3D plotting\n",
        "*   **IPython**: Enhanced interactive console\n",
        "*   **Sympy**: Symbolic mathematics\n",
        "*   **Pandas**: Data structures and analysis\n",
        "\n",
        "***\n"
      ]
    },
    {
      "metadata": {
        "id": "8ZPFc7FDMNgq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TeuCXpS_MN99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "yE90Bj8ega8R",
        "colab_type": "toc"
      },
      "cell_type": "markdown",
      "source": [
        ">[AI NI Academy 1](#scrollTo=Mdv3nR_jb-zG)\n",
        "\n",
        ">[Introduction](#scrollTo=0a1no8G2eyTM)\n",
        "\n",
        ">>[Python](#scrollTo=0a1no8G2eyTM)\n",
        "\n",
        ">>[What is Artificial Intelligence](#scrollTo=cXGM6l0trgxD)\n",
        "\n",
        ">>[What is Machine Learning](#scrollTo=kjSQT--8jYSM)\n",
        "\n",
        ">>[Definitions](#scrollTo=_5sTQ_3AxaBe)\n",
        "\n",
        ">>[Supervised Learning](#scrollTo=8Zwyyoo1mRI9)\n",
        "\n",
        ">>[Unsupervised Learning](#scrollTo=RLDhyFOwnI3v)\n",
        "\n",
        ">>[Eigenfaces & Principle Component Analysis](#scrollTo=kLrGkJ7lFU1s)\n",
        "\n",
        ">>>[Principle Component Analysis (PCA)](#scrollTo=ojIMHU8-Ferj)\n",
        "\n",
        ">>>[How are we going to use this?](#scrollTo=ojIMHU8-Ferj)\n",
        "\n",
        ">[Code](#scrollTo=95uj1H8ufKQC)\n",
        "\n",
        ">>[Imports](#scrollTo=95uj1H8ufKQC)\n",
        "\n",
        ">>[Understanding Your Data](#scrollTo=SI_jTEAw7rLX)\n",
        "\n",
        ">>>[What an Image is](#scrollTo=SI_jTEAw7rLX)\n",
        "\n",
        ">>>[Your grayscale image](#scrollTo=SI_jTEAw7rLX)\n",
        "\n",
        ">>>[Your full colour image](#scrollTo=SI_jTEAw7rLX)\n",
        "\n",
        ">>[Augmentation](#scrollTo=FpT0Rwz1djSj)\n",
        "\n",
        ">>>[Image Augmentation with Keras](#scrollTo=zZi7eP0m73nc)\n",
        "\n",
        ">>>[Image Augmentation with Scikit Learn](#scrollTo=Sm3m-DpF8a0K)\n",
        "\n",
        ">>>[Challenge 1](#scrollTo=nYWQHh_SCwG0)\n",
        "\n",
        ">>[PCA & Model](#scrollTo=NrorfisT8s3f)\n",
        "\n",
        ">>>[Challenge 2](#scrollTo=d7fBZee2zKlE)\n",
        "\n",
        ">>>[What did our eigenfaces look like?](#scrollTo=NJHMNYGdd2Xv)\n",
        "\n",
        ">>[Challenge 3](#scrollTo=UjZmxrvFhZcA)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0a1no8G2eyTM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "***\n",
        "\n",
        "## Python \n",
        "\n",
        "If you are new to Python, don't worry, you should have another notebook called Python 101 that we have shared with you. \n",
        "\n",
        "Try to follow along as best you can, during the workshop you will have time to look through that notebook and make sure to ask any of us if you get stuck. \n",
        "\n",
        "The notebook should be located in the same directory as this one. "
      ]
    },
    {
      "metadata": {
        "id": "cXGM6l0trgxD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## What is Artificial Intelligence\n",
        "\n",
        "**Artificial intelligence (AI)** is currently in still in its conceptual phase. AI is an overarching term many people reference when they are actually talking about machine learning or deep learning.\n",
        "\n",
        "**Artificial Narrow Intelligence (ANG)** is the level of intelligence that we are achieving right now. ANG describes intelligence which can only perform one task very well and nothing else. Having an AI play chess, make purchase recommendations or process natural language are all examples of narrow intelligence. Even self driving cars are considered as a type of narrow9 intelligence, using a collection ANGs.\n",
        "\n",
        "**Aritificial General Intelligence (AGI)** or human level AI can perceive and reason with its environment similar to how a human does. This type of AI is what people tend to think about when just refering to AI. Some people are of the opinion that this level of intelligence is far off while others think it is just around the corner. Once this intelligence in a machine has been achieved it won’t be long after that we hit the level of super intelligence.\n",
        "\n",
        "**Artificial Super Intelligence (ASI)** is when the intelligence becomes much smarter than humans in practically every field.  Once we reach AGI, the rate at which the machine learns increases exponentially until it reaches super intelligence. "
      ]
    },
    {
      "metadata": {
        "id": "kjSQT--8jYSM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## What is Machine Learning\n",
        "\n",
        "![alt text](https://www.usoft.com/getmedia/f443b2fe-7a38-4cb4-b7b4-dc9af660a09a/The-spectrum-of-AI-ML-DL.aspx?width=800&height=279)\n",
        "\n",
        "\n",
        "AI refers to machines that can do more than one task, they are conceptually ‘intelligent’ where they perform tasks based on predictions and data. Machine learning is a subset of AI, at the root ML is a way of achieving AI. ML itself is is disciplined to perform one task and one task well. \n",
        "\n",
        "**Machine Learning** is a discipline of AI where instead of coding a program to perform in a specific way and return an expected answer, we can give the ability to learn how to complete a task to a computer. \n",
        "\n",
        "**Deep Learning** is a subset of machine learning and is inspired by the biology of how human’s learn and how each neuron in our brain  is connected to the other. Deep learning techniques involve using neural networks to learn. A neural network is made up of multiple neurons or nodes which take input from x and output a prediction y. Each input x inputs its data through each neuron. The neural network will figure out each nueron’s feature itself given x and y in the training set. \n",
        "\n",
        "Examples to look at that use deep learning:\n",
        "\n",
        "*  Skype real time translation. \n",
        "*  Nueral Doodle.\n",
        "*  Enlitic, used for medical imaging. \n",
        "*  QuickDraw\n",
        "*  Edges2Cats\n",
        "*  RunwayML\n"
      ]
    },
    {
      "metadata": {
        "id": "_5sTQ_3AxaBe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Definitions\n",
        "\n",
        "**Structured data** represents the likes of databases. Each feature has a well defined meaning. \n",
        "\n",
        "**Unstructured data** covers raw audio, images and text. \n",
        "\n",
        "This step of capturing patterns from data is called **fitting or training the model**.\n",
        "\n",
        "The data used to fit/train the model is called the training data.\n",
        "\n",
        "Computations of a neural network are organised in two ways: \n",
        "\n",
        "* A **forward pass** or a **forward propagation** step where the output of the neural network is computed.\n",
        "* This is followed by a **backward pass** or a **back propagation** step, which is used to compute gradients  or derivatives. \n",
        "\n",
        "**Labels or Classes** are the same thing and it’s down to personal preference which one you use. Whenever we need to classify/label text or an image for a our a prediction we train the machine on data that has been correctly labelled or classified. \n",
        "\n",
        "A model is what we train with our data so we are able to get a computer to learn how to complete the task we want. \n",
        "\n",
        "**Bias and Variance **\n",
        "\n",
        "While developing a machine learning model, the two major sources that produce errors are from bias and variances. Bias denotes the fluctuations in accuracy with changing training data i.e. Underfitting. Variance is the sensitivity of the model to the input data i.e. Overfitting. \n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png)"
      ]
    },
    {
      "metadata": {
        "id": "8Zwyyoo1mRI9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Supervised Learning\n",
        "\n",
        "Refers to the process of building a machine learning model that is based on labelled training data. You have a input variable (x) and output variable (y) and you use an algorithm to learn the mapping function from the inout to the output. \n",
        "\n",
        "```\n",
        "f(x) = y\n",
        "```\n",
        "\n",
        "The algorithm iteratively makes predictions on the training data and is corrected by the data representing the answers. \n",
        "\n",
        "Problems can be grouped in regression and classification: \n",
        "\n",
        "* **Classification** - The output variable is a category. Eg. “disease” and “no disease”\n",
        "* **Regression** - The output variable is a real value. Eg. “price” or “weight” \n",
        "\n",
        "![alt text](https://www.researchgate.net/profile/Yves_Matanga2/publication/326175998/figure/fig9/AS:644582983352328@1530691967314/Classification-vs-Regression.png)"
      ]
    },
    {
      "metadata": {
        "id": "RLDhyFOwnI3v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Unsupervised Learning\n",
        "\n",
        "![alt text](https://qph.fs.quoracdn.net/main-qimg-b6846724daf2af284a1137c1a8e72f56)\n",
        "\n",
        "Unsupervised machine learning is a class of techniques to find patterns that **describe the structure of “unlabled” data** (data that has not been classified or categorised).  In the example above the apples, bananas and oranges are fed to the algorithm without their names. As they are fed through the algorithm, their distinct **features are recognised** and the model is trained to recognise those specific fruits based on how they look. \n",
        "\n",
        "The most common type of unsupervised learning is clustering. Clustering algorithms run through your data and find natural clusters if they exist, e.g K-Means or Hierarchical Clustering, which create clusters based on features of the data.\n",
        "\n",
        "![alt text](https://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/GUID-A06A412D-2F4F-4D35-8FFF-1F4B3B3A8F16-web.png)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kLrGkJ7lFU1s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Eigenfaces & Principle Component Analysis"
      ]
    },
    {
      "metadata": {
        "id": "ojIMHU8-Ferj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Eigenfaces is the name given to eigenvectors (type of linear algebra) when we use them in computer vision to perform facial recognition. They work off a base face and compare how the faces are represented by this base face, it works by analysing the overall face appearance not facial details and highlights the principle components.\n",
        "\n",
        "### Principle Component Analysis (PCA)\n",
        "\n",
        "The objective of principle component analysis is to identify the hyperplane that lies closest to the data points and then project our data points on to that plane to reduce the dimensions (eg. 2D to 1D). \n",
        "\n",
        "\n",
        ">``\n",
        "Projection of 3D to 2D using plane | Finding a Hyperplane\n",
        "--- | ---\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*Wcn_sTqL05a7vHpmxf24Dw.png) |  ![alt text](https://cdn-images-1.medium.com/max/1600/1*XGaA7KWUlhWZLIezYEBIHA.gif)\n",
        "\n",
        "``\n",
        "\n",
        "**But why do we want to reduce dimensionality?**\n",
        "High dimensional data sets are often at risk of being sparse which increases the risk of overfitting and not reliable in lower dimensions. Both these factors then relate to poor model performance.\n",
        "\n",
        "The hyperplane chosen is determined by the axis through the dataset which perserves the maximum amound of variance in our data because we want to keep as much information as possible.\n",
        "\n",
        "\n",
        "### How are we going to use this?\n",
        "\n",
        "We are going to use PCA to create eigenfaces using the SciKit Learn Data set of Labeled Faces in the Wild in order to make a machine learning model that can perform facial recognition. "
      ]
    },
    {
      "metadata": {
        "id": "95uj1H8ufKQC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code\n",
        "\n",
        "## Imports\n",
        "***\n",
        "\n",
        "Before we get started we need to import the appropriate **libraries/modules**, these contain the functions that we will need to use to prepare the data and train the computer to learn. "
      ]
    },
    {
      "metadata": {
        "id": "KB_PvYaU0TRA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UTI_2v18LxhO",
        "colab_type": "code",
        "outputId": "56441c15-df88-4ae5-8cdc-4c592f03d637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "cell_type": "code",
      "source": [
        "lfw_people = fetch_lfw_people(min_faces_per_person=100, resize=0.4)\n",
        "\n",
        "n_samples, h, w = lfw_people.images.shape\n",
        "\n",
        "X = lfw_people.data\n",
        "n_features = X.shape[1]\n",
        "\n",
        "y = lfw_people.target\n",
        "target_names = lfw_people.target_name\n",
        "n_classes = target_names.shape[0]\n",
        "\n",
        "print(\"Total database size:\")\n",
        "print(\"n_samples: %d\" % n_samples)\n",
        "print(\"n_features: %d\" %n_features)\n",
        "print(\"n_classes: %d\" % n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'target_name'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-664fbfd79ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfw_people\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfw_people\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: target_name"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SI_jTEAw7rLX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Understanding Your Data \n",
        "***\n",
        "\n",
        "Machine learning is a great tool but the one thing it relies on is good data. The ability to understand and work with your data to get the most out of it is more important than the actual machine learning itself. With a dataset consisting of images you need to be careful that all the images are relevant to the task. This is also where you need to be careful of having a high bias or high variance and when creating your own set, bias and variance are even more relevant. \n",
        "\n",
        "### What an Image is\n",
        "\n",
        "Images can either be grayscale or RGB (Red, Green, Blue). If the images in the dataset are grayscale then we are only going to be working with a 1D array; the images only consist of black and white. Where as, each RGB image will be represented by a 3D array; each array holds one of the colour (Red, Green or Blue).\n",
        "\n",
        "### Your grayscale image\n",
        "\n",
        "![Grayscale Image Breakdown](https://docs.chainer.org/en/stable/_images/5.png)\n",
        "\n",
        "### Your full colour image\n",
        "\n",
        "![Colour Image Breakdown](https://cdn-images-1.medium.com/max/2000/1*CBY94wikMUCZMB4-Xxs-pw.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FpT0Rwz1djSj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Augmentation\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "zZi7eP0m73nc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Image Augmentation with Keras\n",
        "\n",
        "To achieve more reliable and accurate predictions from our model we are going to augment our images. Augmentation is a method used primarily when working with images rather than text; the need to know the context or meaning of an image is less important than if you were working with text, where semantics and syntax are important. When trying to train a model to classify an image in relation to a specific thing or recognise the presence of something in the image, it is simply a matter of adjusting the values and positions of the pixels in the image to provide us with more variation in our dataset.  \n",
        "\n",
        "To Do: \n",
        "1. Create a folder to hold the images that you are going to generate.\n",
        "2. Pick the image that you want to augment from the lfw_people dataset that we imported at the beginning.\n",
        "3. Modify the image data so that it suits the following format: (1, Height, Width, 1).\n",
        "4. Using the ImageDataGenerator that we imported at the top augment your chosen image with your specified parameters. "
      ]
    },
    {
      "metadata": {
        "id": "NseAp5Mm9DdQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir Preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KhxWBk_D71HP",
        "colab_type": "code",
        "outputId": "657f243b-c9c0-42cc-a517-c69d7f0ee141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "img_face = img_to_array(lfw_people.images[0])\n",
        "img_face = img_face.reshape((1,) + img_face.shape)\n",
        "img_face.shape\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 50, 37, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "R7oGaxdU8KOk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rotation_range=40,\n",
        "                            width_shift_range=0.2,\n",
        "                            height_shift_range=0.2,\n",
        "                            rescale=1./255,\n",
        "                            shear_range=0.2,\n",
        "                            zoom_range=0.2,\n",
        "                            horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r5Lr1ou78QPD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i=0\n",
        "\n",
        "for batch in datagen.flow(img_face, batch_size=1, save_to_dir=\"Preview\", save_format=\"jpeg\"):\n",
        "  i+=1\n",
        "  if i > 20:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3CxjcTst8R6I",
        "colab_type": "code",
        "outputId": "7de44dc4-6ef8-41ae-b090-ebb70e6516d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "!ls Preview"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_0_1037.jpeg  _0_2225.jpeg  _0_3864.jpeg  _0_5177.jpeg\t_0_9266.jpeg\n",
            "_0_1376.jpeg  _0_269.jpeg   _0_4240.jpeg  _0_6672.jpeg\n",
            "_0_1489.jpeg  _0_2960.jpeg  _0_4351.jpeg  _0_7679.jpeg\n",
            "_0_1723.jpeg  _0_3610.jpeg  _0_4578.jpeg  _0_8098.jpeg\n",
            "_0_2166.jpeg  _0_3862.jpeg  _0_5115.jpeg  _0_9073.jpeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sm3m-DpF8a0K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Image Augmentation with Scikit Learn\n",
        "\n",
        "Scikit Learn does not have a function that can do the same as Keras' ImageDataGenerator. We need to write the functionality ourselves, making use of numpy arrays and SciKit Learn's image module/library. \n",
        "\n",
        "To Do:\n",
        "1. Import the relevant modules/libraries.\n",
        "2. Define the functions that will transform our image.\n",
        "3. Define our path to the image and the amount of images that we want to create.\n",
        "4. Write the functionalitry needed to generate the augmented images with a random transformation"
      ]
    },
    {
      "metadata": {
        "id": "RApjYeVQAkH6",
        "colab_type": "code",
        "outputId": "152e273c-7a64-4c98-edd6-2d16f6d896c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Jake-Young/AcademyImages.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AcademyImages'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vmb9mI4U8YcW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from scipy import ndarray\n",
        "\n",
        "# image processing library\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "from skimage import util\n",
        "from skimage import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYWQHh_SCwG0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to define the transformations that will be applied to our images to give us our augmentations. Transformations of images range from simply adjusting the position of the image to flipping it, or adding noise. \n",
        "\n",
        "```python\n",
        "def random_noise(image_array: ndarray)\n",
        "```\n",
        "\n",
        "The random noise function makes use of the ```skimage``` utilities module. This module gives us access to: \n",
        "\n",
        "```python\n",
        "sk.util.random_noise(your image array goes here)\n",
        "```\n",
        "\n",
        "### Challenge 1\n",
        "***\n",
        "\n",
        "For this challenge you will need to define 2 other transformations to augment youe chosen image. Make sure to use the defined transformation as a guide for completing the other two functions.\n",
        "\n",
        "For this challenge you can make use of this import: \n",
        "\n",
        "```python\n",
        "from skimage import transform\n",
        "```\n",
        "\n",
        "To Do:\n",
        "\n",
        "1. Define a function that will rotate the image randomly, either clockwise or counter clockwise. \n",
        "2. Define a function that will flip the image horizontally.\n",
        "3. Define 2 other transformations of your choice. "
      ]
    },
    {
      "metadata": {
        "id": "r7esBHFH8eAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_noise(image_array: ndarray):\n",
        "    # add random noise to the image\n",
        "    return sk.util.random_noise(image_array)\n",
        "  \n",
        "def rotate_image(image_array: ndarray):\n",
        "    random_degree = random.uniform(-25,25)\n",
        "    return sk.transform.rotate(image_array, random_degree)\n",
        "def horizontal_flip(image_array:ndarray):\n",
        "    return image_array[:, ::-1]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_Zs1I568fox",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of the transformations we defined earlier\n",
        "available_transformations = {\n",
        "    'noise': random_noise,\n",
        "    'rotate': rotate_image,\n",
        "    'flip': horizontal_flip\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flepPt9v8hOK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = \"AcademyImages\"\n",
        "desired_amount = 5;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XMyuC93QuWvV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is where we are using the functions that we defined above, but we first need to write some functionality to read our uploaded images, augment them and then save to a specified directory. \n",
        "\n",
        "```python\n",
        "images = [os.path.join(PATH, f) for f in os.listdir(PATH) if os.path.isfile(os.path.join(PATH, f))]\n",
        "```\n",
        "Here we are looking at the path that we specified above for images that can be augmented with out functions. If there is a file (image present) we will join that to the list of previously found files. \n",
        "\n",
        "We are then going to use our desired amount of augmentated images and generate that amount of extra images. Based on the path of our chosen image we are going to choose a random transformation from the dictionary that we defined above. \n",
        "\n",
        "```python\n",
        "available_transformations = {\n",
        "    'rotate': random_rotation,\n",
        "    'noise': random_noise,\n",
        "    'horizontal_flip': horizontal_flip\n",
        "}\n",
        "```\n",
        "\n",
        "With each transformation we will assign it a file name relative to the path that we chose before. We will then save to the folder and add one to the counter that is compared with our desired amount.\n",
        "\n",
        "```python\n",
        "while num_generated_files <= desired_amount\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "vLNoFyho8jsJ",
        "colab_type": "code",
        "outputId": "794010f0-8ad4-47ad-c746-f449ce2298c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# find all files paths from the folder\n",
        "images = [os.path.join(PATH, f) for f in os.listdir(PATH) if os.path.isfile(os.path.join(PATH, f))]\n",
        "\n",
        "num_generated_files = 0\n",
        "while num_generated_files <= desired_amount:\n",
        "    # random image from the folder\n",
        "    image_path = PATH + \"/guru.jpg\"\n",
        "    # read image as an two dimensional array of pixels\n",
        "    image_to_transform = sk.io.imread(image_path)\n",
        "    # random num of transformation to apply\n",
        "    num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
        "\n",
        "    num_transformations = 0\n",
        "    transformed_image = None\n",
        "    while num_transformations <= num_transformations_to_apply:\n",
        "        # random transformation to apply for a single image\n",
        "        key = random.choice(list(available_transformations))\n",
        "        transformed_image = available_transformations[key](image_to_transform)\n",
        "        num_transformations += 1\n",
        "\n",
        "    new_file_path = '%s/augmented_image_%s.jpg' % (PATH, num_generated_files)\n",
        "\n",
        "    # write image to the disk\n",
        "    io.imsave(new_file_path, transformed_image)\n",
        "    num_generated_files += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
            "  .format(dtypeobj_in, dtypeobj_out))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NrorfisT8s3f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PCA & Model\n",
        "***"
      ]
    },
    {
      "metadata": {
        "id": "ROQiQE_9zA58",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To convert our face images into eigenfaces we have to use PCA to reduce the dimensions of the image. By doing PCA we will get a set of general faces that we will train our model on, when training our model we don't want to overfit to data so by reducing dimensions we have also reduced the risk of overfitting. \n",
        "\n",
        "To Do: \n",
        "1. Split the data into training and testing sets.\n",
        "2. Set a variable for the amount of eigenvectors we are reducing the data to\n",
        "3. Create a PCA and fit it to the training data\n",
        "4. Transform the training and testing images using the PCA \n"
      ]
    },
    {
      "metadata": {
        "id": "UQTolC5zOYBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split into a training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4_Njd08fObQU",
        "colab_type": "code",
        "outputId": "1749fd63-ea0e-4b5b-d134-f9a43a59acbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled dataset): unsupervised feature extraction / dimensionality reduction.\n",
        "\n",
        "n_components = 150\n",
        "\n",
        "print(\"Extracting the top %d eigenfaces from %d faces\"\n",
        "      % (n_components, X_train.shape[0]))\n",
        "\n",
        "# whiten = true -> removes the noise and irrelevant information from the images (caused by image granularity)\n",
        "# randomised -> type of PCA paramter that reduces the number of features randomly\n",
        "# n_components -> output dimensionality (the number of eigenvectors to project onto), that we want to reduce down to, in our case 150 faces from 912\n",
        "# .fit() -> PCA is computing the vectors to project data on to that wil reduce the dimensions \n",
        "# .transform() -> computes the projection \n",
        "# fit off the training data and perform the transform on training and testing data \n",
        "\n",
        "pca = PCA(n_components = n_components, svd_solver = \"randomized\", whiten = True).fit(X_train)\n",
        "\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting the top 150 eigenfaces from 912 faces\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZazaNyk0sMdW",
        "colab_type": "code",
        "outputId": "6cdf6c3e-0d45-4731-ffa2-e75a7ad75064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train_pca.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(912, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "shyDAc84zE33",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At this point we are ready to create and train our model, we want to create an optimum prediction so we will start off by testing parameters to find the best ones for our model. \n",
        "\n",
        "To do: \n",
        "\n",
        "1. Create a grid of parameters to test\n",
        "2. Create a grid search to find the best parameters\n",
        "3. Train the model with the training data\n",
        "4. Predict for the test data\n",
        "5. Print out a classification report and confusion matrix to see the performance of you model\n",
        "6. Visualise the images and predictions that you made \n",
        "7. Visualise the eigenfaces\n",
        "\n",
        "\n",
        "Here we have different parameters, **C**, **Kernel** and **Gamma**. The graphs below show the effects different parameter values have on the data points.\n",
        "\n",
        "**C** \n",
        "\n",
        "C is the penalty parameter of the error term. It controls the trade off between smooth decision boundary and classifying the training points correctly. Increasing C values can lead to overfitting the training data.\n",
        "\n",
        ">``\n",
        "c = 0.1 | c = 10\n",
        "--- | ---\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*8Lyd7_IJtjJ3A5NOUgB3RQ.png) |  ![alt text](https://cdn-images-1.medium.com/max/1600/1*ZuwTKzONlqV9ntB9GMax2g.png)\n",
        "\n",
        "``\n",
        "\n",
        "\n",
        "**Kernel** \n",
        "\n",
        "Kernel selects the type of hyperplane used to separate the data. In our case we are using \"rbf\" which is a non-linear hyperplane.\n",
        "\n",
        ">``\n",
        "Linear Kernal | Non-Linear Kernal\n",
        "--- | ---\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*u_168Q0FwVXMW-HFbFxNFg.png) |  ![alt text](https://cdn-images-1.medium.com/max/1600/1*sNoaEibNf5Msw58DZ8FuJg.png)\n",
        "\n",
        "``\n",
        "\n",
        "\n",
        "**Gamma** \n",
        "\n",
        "Gamma is a variable for creating non linear hyperplanes. We want the hyperplanes to not overfit to our data points so we keep gamma at a low number.\n",
        "\n",
        ">``\n",
        "Gamma = 0.1 | Gamma = 10\n",
        "--- | ---\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*YLuGuFzYpgRYstACQoojPA.png) |  ![alt text](https://cdn-images-1.medium.com/max/1600/1*tKvjLRbt5yiPKhEtGnI_hQ.png)\n",
        "\n",
        "``"
      ]
    },
    {
      "metadata": {
        "id": "3Zu5l_fsOlKk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train a SVM classification model\n",
        "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
        "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
        "\n",
        "\n",
        "# array of params to test against to find the best \n",
        "\n",
        "\n",
        "print(\"Best estimator found by grid search:\")\n",
        "print(clf.best_estimator_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7fBZee2zKlE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Challenge 2\n",
        "\n",
        "Now you have the model made see if you can predict off it and produce the reports. By the end of this challenge we will have our predictions, know how well our model performed and print out the faces with the predictions.\n",
        "\n",
        "To do:\n",
        "\n",
        "1. Predict off of the model for your test data\n",
        "2. Produce a classification report \n",
        "3. Produce a confusion matrix\n",
        "4. Use the functions given below to print out the face images with their predicted titles - play about with the functions to see how many you can print out. "
      ]
    },
    {
      "metadata": {
        "id": "eLazRMwpPG5T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gwT9vWeHZor9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "def plot_gallery(images, titles, h, w, rows=3, cols=4):\n",
        "    plt.figure()\n",
        "    for i in range(rows * cols):\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
        "        plt.title(titles[i])\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "\n",
        "def titles(y_pred, y_test, target_names):\n",
        "    for i in range(y_pred.shape[0]):\n",
        "        pred_name = target_names[y_pred[i]].split(' ')[-1]\n",
        "        true_name = target_names[y_test[i]].split(' ')[-1]\n",
        "        yield 'predicted: {0}\\ntrue: {1}'.format(pred_name, true_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfTlFNrv7kob",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJHMNYGdd2Xv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### What did our eigenfaces look like?\n",
        "\n",
        "The predictions use the eigenfaces below to predict which one the new face image is like.\n",
        "\n",
        "We can reshape those eigenvectors into images and visualize the eigenfaces. These represent the “generic” faces of our dataset."
      ]
    },
    {
      "metadata": {
        "id": "fbwHgKkIdoQk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UjZmxrvFhZcA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Challenge 3\n",
        "***\n",
        "\n",
        "For the third and final challenge we are going to throw you in the deep end :) We recommend that you partner up for this challenge or work in grgoups to solve it. \n",
        "\n",
        "Using the imports that we have given we want you to classifiy the MNIST data that is provided through sklearn using the ```KNeighborsClassifier```.\n",
        "\n",
        "To Do: \n",
        "\n",
        "1. Load in your data and assign it to a variable.\n",
        "2. Define how much training (X) and testing (Y) data the you want to use. \n",
        "3. Combine the images and their classes into a list.\n",
        "4. Train your model.\n",
        "5. Gather the expected labels and the predicted labels.\n",
        "6. Print out the accuracy and the classification report.\n",
        "7. **Bonus**: Print out a grid of MNIST numbers with their predicted label. "
      ]
    },
    {
      "metadata": {
        "id": "484XeKkZjKP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4FepvyTr2h8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load in your data and assign it to a variable\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "#Define how much training (X) and testing (Y) data the you want to use. \n",
        "\n",
        "\n",
        "#Combine the images and their classes into a list.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "auCdJDjt2uvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Flatten data so that it only consists of number samples and their features\n",
        "\n",
        "\n",
        "print(digits.images.shape)\n",
        "print(data.shape)\n",
        "print(data[0]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZ5hkXoj24Bq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = KNeighborsClassifier()\n",
        "\n",
        "#Train\n",
        "\n",
        "\n",
        "#gather the expected and predicted labels from the data set\n",
        "\n",
        "\n",
        "#predict the labels using the model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6NuU5La3Jp5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Print out the accuracy and the classification report.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I-Dp6LCM3Sgs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Try manually calculating the accuracy and printing it. It should be the same as above.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zYY08W_J3cuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#BONUS - create a zipped list of the images and their predicted lables and plot a range out \n",
        "images_and_predictions = list(zip(digits.images[training_volume:training_volume + testing_volume], predicted))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}